"""
ä¿®å¤ç‰ˆFaceProcessor - è§£å†³æ£€æµ‹é€»è¾‘é—®é¢˜
"""

import cv2
import numpy as np
import os
from ultralytics import YOLO

class FaceProcessor:
    def __init__(self, target_size=112):
        self.target_size = target_size
        self.model = YOLO("yolov8n.pt")
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        print(f"âœ… FaceProcessoråˆå§‹åŒ–å®Œæˆ")

    def detect_faces(self, image):
        """ä¿®å¤ç‰ˆäººè„¸æ£€æµ‹ - åŸºäºè¯Šæ–­ç»“æœ"""

        # YOLOäººç‰©æ£€æµ‹ï¼ˆå·²éªŒè¯æ­£å¸¸ï¼‰
        results = self.model(image, verbose=False)

        all_faces = []

        for result in results:
            if result.boxes is not None:
                for box in result.boxes:
                    cls = int(box.cls[0])
                    conf = float(box.conf[0])

                    # äººç‰©æ£€æµ‹ï¼ˆåŸºäºä½ çš„è¯Šæ–­ç»“æœï¼šç½®ä¿¡åº¦0.8-0.9ï¼‰
                    if cls == 0 and conf > 0.2:  # é™ä½é˜ˆå€¼ï¼ŒåŸºäºä½ çš„0.8+ç»“æœ
                        x1, y1, x2, y2 = box.xyxy[0].tolist()
                        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)

                        # åœ¨äººç‰©åŒºåŸŸå†…æ£€æµ‹äººè„¸ï¼ˆå·²éªŒè¯æ­£å¸¸ï¼‰
                        person_roi = image[y1:y2, x1:x2]
                        if person_roi.size == 0:
                            continue

                        # äººè„¸æ£€æµ‹ï¼ˆåŸºäºä½ çš„è¯Šæ–­ç»“æœï¼šæ¯å¼ å›¾1å¼ äººè„¸ï¼‰
                        gray_roi = cv2.cvtColor(person_roi, cv2.COLOR_BGR2GRAY)
                        face_rects = self.face_cascade.detectMultiScale(
                            gray_roi,
                            scaleFactor=1.05,  # æ›´ç²¾ç»†ï¼ˆä½ çš„è¯Šæ–­æ˜¾ç¤º1.05æœ‰æ•ˆï¼‰
                            minNeighbors=3,    # æ›´å®½æ¾ï¼ˆä½ çš„è¯Šæ–­æ˜¾ç¤º3æœ‰æ•ˆï¼‰
                            minSize=(20, 20)   # æ›´å°ï¼ˆä½ çš„è¯Šæ–­æ˜¾ç¤º20æœ‰æ•ˆï¼‰
                        )

                        # å…³é”®ä¿®å¤ï¼šæ­£ç¡®å¤„ç†æ¯ä¸ªæ£€æµ‹åˆ°çš„äººè„¸
                        for fx, fy, fw, fh in face_rects:
                            # è½¬æ¢å›å…¨å›¾åæ ‡
                            face_x1 = x1 + fx
                            face_y1 = y1 + fy
                            face_x2 = face_x1 + fw
                            face_y2 = face_y1 + fh

                            # æ„é€ å…³é”®ç‚¹
                            landmarks = [
                                (face_x1 + fw//4, face_y1 + fh//4),
                                (face_x1 + 3*fw//4, face_y1 + fh//4),
                                (face_x1 + fw//2, face_y1 + fh//2),
                                (face_x1 + fw//4, face_y1 + 3*fh//4),
                                (face_x1 + 3*fw//4, face_y1 + 3*fh//4)
                            ]

                            face_info = {
                                'box': (face_x1, face_y1, face_x2, face_y2),
                                'landmarks': landmarks,
                                'confidence': conf * 0.9,  # åŸºäºä½ çš„é«˜ç½®ä¿¡åº¦
                                'source': 'yolo+opencv'
                            }
                            all_faces.append(face_info)

        return all_faces

    def align_face(self, image, landmarks):
        """äººè„¸å¯¹é½"""
        left_eye = landmarks[0]
        right_eye = landmarks[1]

        dy = right_eye[1] - left_eye[1]
        dx = right_eye[0] - left_eye[0]
        angle = np.degrees(np.arctan2(dy, dx))

        desired_eye_distance = 60
        current_eye_distance = np.sqrt(dx**2 + dy**2)
        scale = desired_eye_distance / current_eye_distance if current_eye_distance > 0 else 1.0

        eyes_center = (float(left_eye[0] + right_eye[0]) / 2,
                       float(left_eye[1] + right_eye[1]) / 2)

        rotation_matrix = cv2.getRotationMatrix2D(eyes_center, angle, scale)
        rotation_matrix[0, 2] += self.target_size // 2 - eyes_center[0]
        rotation_matrix[1, 2] += self.target_size // 3 - eyes_center[1]

        aligned_face = cv2.warpAffine(
            image, rotation_matrix,
            (self.target_size, self.target_size),
            flags=cv2.INTER_CUBIC,
            borderMode=cv2.BORDER_REPLICATE
        )

        return aligned_face

    def enhance_face(self, face_img):
        """äººè„¸å¢å¼º"""
        ycrcb = cv2.cvtColor(face_img, cv2.COLOR_BGR2YCrCb)
        ycrcb[:, :, 0] = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8)).apply(ycrcb[:, :, 0])
        enhanced = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)
        return enhanced

    def process_image(self, image_path):
        """ä¸»å¤„ç†æµç¨‹"""
        import numpy as np
        file_bytes = np.fromfile(image_path, dtype=np.uint8)
        image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")

        # æ£€æµ‹äººè„¸ï¼ˆä½¿ç”¨ä¿®å¤ç‰ˆæ£€æµ‹ï¼‰
        faces = self.detect_faces(image)
        print(f"æ£€æµ‹åˆ° {len(faces)} å¼ äººè„¸")

        results = []
        for i, face_data in enumerate(faces):
            x1, y1, x2, y2 = face_data['box']
            landmarks = face_data['landmarks']

            # è£å‰ªå¹¶å¯¹é½äººè„¸
            aligned_face = self.align_face(image, landmarks)

            # å¢å¼ºå¤„ç†
            enhanced_face = self.enhance_face(aligned_face)

            result = {
                'face_img': enhanced_face,  # 112x112 BGR
                'box': (x1, y1, x2, y2),
                'confidence': face_data['confidence'],
                'person_id': f"face_{i+1}"
            }
            results.append(result)

        return results

    def batch_process_folder(self, input_folder, output_folder):
        """æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹"""
        os.makedirs(output_folder, exist_ok=True)

        image_extensions = ['.jpg', '.jpeg', '.png', '.webp', '.bmp']
        image_files = []

        for file in os.listdir(input_folder):
            if any(file.lower().endswith(ext) for ext in image_extensions):
                image_files.append(os.path.join(input_folder, file))

        print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")

        for image_file in image_files:
            try:
                results = self.process_image(image_file)

                base_name = os.path.splitext(os.path.basename(image_file))[0]

                for i, result in enumerate(results):
                    output_path = os.path.join(output_folder, f"{base_name}_face_{i + 1}.jpg")
                    cv2.imwrite(output_path, result['face_img'])

                    coord_path = os.path.join(output_folder, f"{base_name}_face_{i + 1}_coords.txt")
                    with open(coord_path, 'w') as f:
                        f.write(f"box: {result['box']}\n")
                        f.write(f"confidence: {result['confidence']}\n")

                print(f"âœ… å¤„ç†å®Œæˆ: {os.path.basename(image_file)} -> {len(results)} å¼ äººè„¸")

            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {image_file} - {e}")

    def final_output(self, input_folder='test_images', output_folder='output_faces'):
        """æœ€ç»ˆè¾“å‡º - ä¸“ç”¨æ–‡ä»¶å¤¹ + å›ºå®šæ ¼å¼"""

        print("ğŸš€ æœ€ç»ˆè¾“å‡ºåˆ°ä¸“ç”¨æ–‡ä»¶å¤¹")
        print(f"è¾“å…¥: {input_folder}")
        print(f"è¾“å‡º: {output_folder}")

        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
        os.makedirs(output_folder, exist_ok=True)

        # ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ï¼ˆ100%æ­£ç¡®ï¼‰
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        input_abs = os.path.join(project_root, input_folder)
        output_abs = os.path.join(project_root, output_folder)

        print(f"ç»å¯¹è·¯å¾„è¾“å…¥: {input_abs}")
        print(f"ç»å¯¹è·¯å¾„è¾“å‡º: {output_abs}")

        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
        if not os.path.exists(input_abs):
            print(f"âŒ è¾“å…¥æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {input_abs}")
            return

        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_files = []
        for file in os.listdir(input_abs):
            if any(ext in file.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp', '.bmp']):
                image_files.append(os.path.join(input_abs, file))

        print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")

        # å¤„ç†æ¯å¼ å›¾ç‰‡
        for image_file in image_files:
            try:
                results = self.process_image(image_file)

                base_name = os.path.splitext(os.path.basename(image_file))[0]

                for i, result in enumerate(results):
                    # è¾“å‡ºåˆ°æŒ‡å®šæ–‡ä»¶å¤¹
                    face_output = os.path.join(output_abs, f"{base_name}_face_{i + 1}.jpg")
                    cv2.imwrite(face_output, result['face_img'])

                    # è¾“å‡ºåæ ‡ä¿¡æ¯åˆ°æŒ‡å®šæ–‡ä»¶å¤¹
                    coord_output = os.path.join(output_abs, f"{base_name}_face_{i + 1}_coords.txt")
                    with open(coord_output, 'w') as f:
                        f.write(f"box: {result['box']}\n")
                        f.write(f"confidence: {result['confidence']}\n")
                        f.write(f"shape: (112, 112, 3)\n")
                        f.write(f"format: BGR\n")

                    print(f"âœ… è¾“å‡º: {face_output}")
                    print(f"âœ… è¾“å‡º: {coord_output}")

            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥: {image_file} - {e}")

        print("\nâœ… æœ€ç»ˆè¾“å‡ºå®Œæˆï¼")



if __name__ == "__main__":
    print("ğŸš€ ç›´æ¥è¿è¡Œface_processoræœ€ç»ˆè¾“å‡º")
    print("=" * 50)

    processor = FaceProcessor(target_size=112)

    # ç›´æ¥è¿è¡Œæœ€ç»ˆè¾“å‡ºåˆ°ä¸“ç”¨æ–‡ä»¶å¤¹
    processor.final_output(input_folder=r'D:\é™ˆé”¡ç¿˜\face_yolo_project\test_images',
                           output_folder=r'D:\é™ˆé”¡ç¿˜\face_yolo_project\output_faces')

    print("\nâœ… ç›´æ¥è¿è¡Œå®Œæˆï¼")